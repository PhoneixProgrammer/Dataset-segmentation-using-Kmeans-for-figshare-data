{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Basic Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\vasavi bondapalli\\anaconda3\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\vasavi bondapalli\\anaconda3\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\vasavi bondapalli\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\vasavi bondapalli\\anaconda3\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vasavi bondapalli\\anaconda3\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\vasavi bondapalli\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading plotly-5.4.0-py2.py3-none-any.whl (25.3 MB)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: six in c:\\users\\vasavi bondapalli\\anaconda3\\lib\\site-packages (from plotly) (1.16.0)\n",
      "Installing collected packages: tenacity, plotly\n",
      "Successfully installed plotly-5.4.0 tenacity-8.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.8.1.tar.gz (220 kB)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\vasavi bondapalli\\anaconda3\\lib\\site-packages (from wordcloud) (1.20.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\vasavi bondapalli\\anaconda3\\lib\\site-packages (from wordcloud) (8.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\vasavi bondapalli\\anaconda3\\lib\\site-packages (from wordcloud) (3.4.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\vasavi bondapalli\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\vasavi bondapalli\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\vasavi bondapalli\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vasavi bondapalli\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: six in c:\\users\\vasavi bondapalli\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.16.0)\n",
      "Building wheels for collected packages: wordcloud\n",
      "  Building wheel for wordcloud (setup.py): started\n",
      "  Building wheel for wordcloud (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for wordcloud\n",
      "Failed to build wordcloud\n",
      "Installing collected packages: wordcloud\n",
      "    Running setup.py install for wordcloud: started\n",
      "    Running setup.py install for wordcloud: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\Vasavi Bondapalli\\anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Vasavi Bondapalli\\\\AppData\\\\Local\\\\Temp\\\\pip-install-hmf66b1f\\\\wordcloud_0c43272736244ffb98a5c953eba52691\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Vasavi Bondapalli\\\\AppData\\\\Local\\\\Temp\\\\pip-install-hmf66b1f\\\\wordcloud_0c43272736244ffb98a5c953eba52691\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\Vasavi Bondapalli\\AppData\\Local\\Temp\\pip-wheel-6g5vre3l'\n",
      "       cwd: C:\\Users\\Vasavi Bondapalli\\AppData\\Local\\Temp\\pip-install-hmf66b1f\\wordcloud_0c43272736244ffb98a5c953eba52691\\\n",
      "  Complete output (20 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.9\n",
      "  creating build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\color_from_image.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\tokenization.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\wordcloud.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\wordcloud_cli.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\_version.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\__init__.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\__main__.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\stopwords -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\DroidSansMono.ttf -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  UPDATING build\\lib.win-amd64-3.9\\wordcloud/_version.py\n",
      "  set build\\lib.win-amd64-3.9\\wordcloud/_version.py to '1.8.1'\n",
      "  running build_ext\n",
      "  building 'wordcloud.query_integral_image' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for wordcloud\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\Vasavi Bondapalli\\anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Vasavi Bondapalli\\\\AppData\\\\Local\\\\Temp\\\\pip-install-hmf66b1f\\\\wordcloud_0c43272736244ffb98a5c953eba52691\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Vasavi Bondapalli\\\\AppData\\\\Local\\\\Temp\\\\pip-install-hmf66b1f\\\\wordcloud_0c43272736244ffb98a5c953eba52691\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\Vasavi Bondapalli\\AppData\\Local\\Temp\\pip-record-qu81w56y\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\Vasavi Bondapalli\\anaconda3\\Include\\wordcloud'\n",
      "         cwd: C:\\Users\\Vasavi Bondapalli\\AppData\\Local\\Temp\\pip-install-hmf66b1f\\wordcloud_0c43272736244ffb98a5c953eba52691\\\n",
      "    Complete output (20 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib.win-amd64-3.9\n",
      "    creating build\\lib.win-amd64-3.9\\wordcloud\n",
      "    copying wordcloud\\color_from_image.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "    copying wordcloud\\tokenization.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "    copying wordcloud\\wordcloud.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "    copying wordcloud\\wordcloud_cli.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "    copying wordcloud\\_version.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "    copying wordcloud\\__init__.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "    copying wordcloud\\__main__.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "    copying wordcloud\\stopwords -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "    copying wordcloud\\DroidSansMono.ttf -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "    UPDATING build\\lib.win-amd64-3.9\\wordcloud/_version.py\n",
      "    set build\\lib.win-amd64-3.9\\wordcloud/_version.py to '1.8.1'\n",
      "    running build_ext\n",
      "    building 'wordcloud.query_integral_image' extension\n",
      "    error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Users\\Vasavi Bondapalli\\anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Vasavi Bondapalli\\\\AppData\\\\Local\\\\Temp\\\\pip-install-hmf66b1f\\\\wordcloud_0c43272736244ffb98a5c953eba52691\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Vasavi Bondapalli\\\\AppData\\\\Local\\\\Temp\\\\pip-install-hmf66b1f\\\\wordcloud_0c43272736244ffb98a5c953eba52691\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\Vasavi Bondapalli\\AppData\\Local\\Temp\\pip-record-qu81w56y\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\Vasavi Bondapalli\\anaconda3\\Include\\wordcloud' Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib.pylab import rcParams\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting environment to ignore future warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Changing Default figure size for EDA\n",
    "%matplotlib inline\n",
    "rcParams[\"figure.figsize\"] = (14, 7)\n",
    "\n",
    "# Changing max columns and rows to be displayed\n",
    "pd.set_option('max_columns', 50)\n",
    "pd.set_option('max_rows', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset & Checcking Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Altmetrics of datasets on Fig Share.csv\", encoding = \"ISO-8859-1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in the dataset we have **31544** rows and **45** columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can see that there are some fields that are completley null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking information of data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking datatype of each column\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's chcek the statistical properties of numeric features\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's chcek the statistical properties of categorical features\n",
    "df.describe(include=['O']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Numerical and Categorical columns Separately\n",
    "cat_cols = df.select_dtypes(np.object).columns\n",
    "num_cols = df.select_dtypes(np.number).columns\n",
    "\n",
    "# Printing the Numerical columns\n",
    "print(\"Dataset has following Numerical columns...\")\n",
    "for i, j in enumerate(num_cols):\n",
    "    print(f\" {i+1}) {j}\")\n",
    "\n",
    "# Printing the Categorical columns\n",
    "print(\"\\n\\nDataset has following Categorical columns...\")\n",
    "for i, j in enumerate(cat_cols):\n",
    "    print(f\" {i+1}) {j}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try to check the percentage of missing values,unique values,percentage of one catagory values and type against each column.\n",
    "def statistics(df):\n",
    "    stats = []\n",
    "    for col in df.columns:\n",
    "        stats.append((col, df[col].nunique(), df[col].isnull().sum(), df[col].isnull().sum() * 100 / df.shape[0], df[col].dtype))\n",
    "\n",
    "    stats_df = pd.DataFrame ( stats , columns = ['Feature' , 'Unique_values' , 'Missing values' , 'Percentage of Missing Values', 'Data Type'])\n",
    "    stats_df.set_index('Feature', drop=True, inplace=True)\n",
    "    stats_df.drop(stats_df[stats_df['Missing values'] == 0].index, axis=0, inplace=True)\n",
    "    stats_df.sort_values('Percentage of Missing Values', ascending=False, inplace=True)\n",
    "    return stats_df\n",
    "\n",
    "stats = statistics(df)\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can see that there are almost 15 to 17 faetures in which almost more than 80 percent data in null and they have only 20 percent data in whole column. So, from 20 percent data we can generate 80 percent data so we have to drop such columns. Let's drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking out the columns having null values more than 70 percent\n",
    "cols = stats [ stats [ \"Percentage of Missing Values\" ] > 70].index\n",
    "df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, these are the features in which almost more 70 percent is null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dropping features that we took out from above \n",
    "df.drop( cols , axis = 1 , inplace = True )\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have dropped 45 - 28 = 17 seventeen feaures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop URLs\n",
    "df.drop ( [ \"Details Page URL\" , \"Badge URL\" , \"DOI\"] , axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping date\n",
    "df.drop(\"Publication Date\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop records in which title is NAN\n",
    "index = df [ df.Title.isnull() ].index\n",
    "df.drop( index , axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find the lenthg of title\n",
    "def get_len(x):\n",
    "    x = str(x)\n",
    "    x = x.split()\n",
    "    x = len(x)\n",
    "    return x\n",
    "\n",
    "df[\"title_len\"] = df.Title.apply(get_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check categories and their frequency in Journal column\n",
    "df[\"Journal/Collection Title\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fill null values in journal feature with the most frequent value.\n",
    "df[\"Journal/Collection Title\"].fillna(df[\"Journal/Collection Title\"].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Severe outliers from Attesntion feature\n",
    "index = df[df[\"Altmetric Attention Score\"] > 500].index\n",
    "df.drop(index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the final data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of finnal data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this all cleaning process we lost **18** records. And almost 20 features that almost empty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot_with_per(feature, title=\"\", limited=False, n=10, color=\"icefire\"):\n",
    "    print(\"Total unique values are: \", len(feature.value_counts()), \"\\n\\n\")\n",
    "    print(\"Category\\tValue\\n\")\n",
    "    if limited:\n",
    "        data = feature.value_counts()[0:n]\n",
    "    else:\n",
    "        data = feature.value_counts()\n",
    "    print(data)\n",
    "    categories_num = len(data)\n",
    "    #plotting bar-plot and pie chart\n",
    "    sns.set_style('darkgrid')\n",
    "    plt.figure(figsize=(16,5))\n",
    "    plt.title(title, fontsize=18)\n",
    "    plt.xlabel(\"Categories\", fontsize=15)\n",
    "    plt.ylabel(\"Count\", fontsize=15)\n",
    "    plt.xticks(rotation=45)\n",
    "    plot = sns.barplot(x=data.index, y=data.values, edgecolor=\"white\", palette=sns.palettes.color_palette(color))\n",
    "    total = len(feature)\n",
    "    for p in plot.patches:\n",
    "        percentage = '{:.1f}%'.format(100 * p.get_height()/total)\n",
    "        x = p.get_x() + p.get_width() / 2 - 0.08\n",
    "        y = p.get_y() + p.get_height()\n",
    "        plot.annotate(percentage, (x, y), size = 12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot_with_per(df[\"Journal/Collection Title\"], \"Distribution of Collection Title Feature\", limited=True, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot_with_per(df[\"Output Type\"], \"Distribution of Output Type Feature\", limited=True, n=10, color=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot_with_per(df[\"OA Status\"], \"Distribution of OA Status Feature\", limited=True, n=10, color=\"Wistia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above visualization we get following information\n",
    "- **Journal/Collection Title** is categorical variable having 69 categories. Almost 90% values are belonging to only one category that is **Figshare**.\n",
    "- Feature named **Output Type** is also a categorical variable and has only a single value **Dataset**. That's mean this variable is constant, there is no change in the values of column. So, this feature will not make any impact on our final results so we will drop them.\n",
    "- **OA Status** aslo a categorical variable having boolean values. But almost 98 percent values are Flase and only 2 percent are True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping constant feature\n",
    "df.drop(\"Output Type\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the average attention score distributed among the categories of categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cat_plots(x, y, title=\"\", xlable=\"\", ylable=\"\", palette=\"Blues_d\"):    \n",
    "    #plotting bar-plot and pie chart\n",
    "    sns.set_style('darkgrid')\n",
    "    plt.figure(figsize=(16,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    sns.barplot(x, y, palette=palette)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel(xlable, fontsize=12)\n",
    "    plt.ylabel(ylable, fontsize=12)\n",
    "    plt.xticks(rotation=65)\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    categories_num = len(x)\n",
    "    plt.pie(x=y, autopct=\"%.1f%%\", explode=[0.08]*categories_num, labels=x, pctdistance=0.5)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df.groupby(by=\"Journal/Collection Title\")[\"Altmetric Attention Score\"].mean().sort_values()[-10 : -1]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_cat_plots(temp.index, temp.values, \"Average Attention Score w.r.t Journal Title Feature\", \"Categories of Collection Title\", \"Attention Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df.groupby(by=\"OA Status\")[\"Altmetric Attention Score\"].mean().sort_values()\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_cat_plots(temp.index, temp.values, \"Average Attention Score w.r.t OA Status\", \"Categories of OA Status\", \"Attention Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above two graphs following information is extracted.\n",
    "- In feature **Journal/Collection Title** the categories *JRC Data Catogloge and Ciência & Saúde Coletiva* has the highest average attention score.\n",
    "- In feature **OA Status** average attention acore is high for True value even we have only 2 percent data for this value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make wordcloud for title column to see the most common words used in title of datasets on figshare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating WordCloud\n",
    "comment_words = ''\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "# iterate through the csv file\n",
    "for val in df.Title:\n",
    "    # typecaste each val to string\n",
    "    val = str(val)\n",
    "    # split the value\n",
    "    tokens = val.split()\n",
    "\n",
    "    # Converts each token into lowercase\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = tokens[i].lower()\n",
    "    comment_words += \" \".join(tokens)+\" \"\n",
    "\n",
    "wordcloud = WordCloud(width = 1200, height = 700, background_color ='gray',\n",
    "      stopwords = stopwords,\n",
    "      min_font_size = 10).generate(comment_words)\n",
    "\n",
    "# plot the WordCloud image\n",
    "plt.figure(figsize = (12, 7), facecolor = None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most common words have been displayed in figure with higher font. Some of the words are given below.\n",
    " - Data, Gaussian, JOb, Effect, Population, Archive, Evolution\n",
    " \n",
    "Now we will drop title feature because it has no worth for further procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping title feature\n",
    "df.drop( \"Title\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the relationship between categorical features and attention score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_stripplot(x, y, xlable, ylable):\n",
    "    sns.stripplot(x, y)\n",
    "    plt.xlabel(xlable, fontsize=14)\n",
    "    plt.ylabel(ylable, fontsize=14)\n",
    "    plt.xticks(rotation=65)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_stripplot(df[\"OA Status\"], df[\"Altmetric Attention Score\"], \"Categories\", \"Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_stripplot(df[\"Journal/Collection Title\"], df[\"Altmetric Attention Score\"], \"Categories\", \"Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_scatterplot(x, y=\"Altmetric Attention Score\"):\n",
    "    plt.scatter(df[x], df[y])\n",
    "    plt.xlabel(x, fontsize=14)\n",
    "    plt.ylabel(\"Attention Score\", fontsize=14)\n",
    "    plt.title(\"Relationship b/w Attention score and \" + x)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in df.columns[4:]:\n",
    "    print(\"Graph for \", i)\n",
    "    make_scatterplot(i)\n",
    "    print(\"\\n\\n\", \"=\"*120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "for i in [\"OA Status\", \"Journal/Collection Title\"]:\n",
    "    df[i] = encoder.fit_transform(df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "sns.heatmap(df.corr(), annot=True, vmin=-1, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can that 3 faetures are constant so we all drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"LinkedIn mentions\", \"F1000 mentions\", \"Syllabi mentions\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reseting index\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking final data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's find best number of clusters using Elbow method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss=[]\n",
    "number_clusters = range(1,7)\n",
    "for i in range(1,7):\n",
    "    kmeans = KMeans(i)\n",
    "    kmeans.fit(df)\n",
    "    wcss_iter = kmeans.inertia_\n",
    "    wcss.append(wcss_iter)\n",
    "\n",
    "plt.plot(number_clusters,wcss)\n",
    "plt.title('The Elbow Method', fontsize=18)\n",
    "plt.xlabel('Number of clusters', fontsize=16)\n",
    "plt.ylabel('WCSS', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this graph we can see that the elbow is mad at x value 2. That's mean the best number of clusters are 2 for our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's build final K mean model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters = 3, init = \"k-means++\", random_state = 42)\n",
    "y_kmeans = model.fit_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_kmeans).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_k = df.copy()\n",
    "df_k[\"Cluster\"] = y_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating both cluster's data\n",
    "cluster0 = df_k[df_k.Cluster == 0]\n",
    "cluster1 = df_k[df_k.Cluster == 1]\n",
    "cluster2 = df_k[df_k.Cluster == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c0_stat = cluster0.describe()\n",
    "c0_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_stat = cluster1.describe()\n",
    "c1_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_stat = cluster2.describe()\n",
    "c2_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_means = pd.DataFrame([c0_stat.T.loc[: , \"mean\"], c1_stat.T.loc[: , \"mean\"], c2_stat.T.loc[: , \"mean\"]]).T\n",
    "c_means.columns = [\"Cluster_0 Mean\", \"Cluster_1 Mean\", \"Cluster_2 Mean\"]\n",
    "c_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_clusterplot(x):\n",
    "    plt.scatter(cluster0[x], cluster0[\"Altmetric Attention Score\"], color=\"blue\", label=\"Cluster 0\")\n",
    "    plt.scatter(cluster1[x], cluster1[\"Altmetric Attention Score\"], color=\"red\", label=\"Cluster 1\")\n",
    "    plt.scatter(cluster2[x], cluster2[\"Altmetric Attention Score\"], color=\"green\", label=\"Cluster 2\")\n",
    "    plt.title(\"Relationship b/w Altmetric Attention Score & \" + x, fontsize=19)\n",
    "    plt.ylabel(\"Altmetric Attention Score\", fontsize=15)\n",
    "    plt.xlabel(x, fontsize=15)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in cluster0.columns[3 : -2 ]:\n",
    "    print(\"Graph for \", i)\n",
    "    make_clusterplot(i)\n",
    "    print(\"\\n\\n\", \"=\"*120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting Words in this File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"Clustering Figshare datasets.ipynb\", \"rt\")\n",
    "data = file.read()\n",
    "words = data.split()\n",
    "\n",
    "print('Number of words in text file :', len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
